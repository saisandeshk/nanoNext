# Full 96-layer NanoNext configuration matching Qwen3-Next architecture.
vocab_size: 151936
hidden_size: 3072
intermediate_size: 5632
num_hidden_layers: 96
num_attention_heads: 16
num_key_value_heads: 2
head_dim: 256
linear_key_head_dim: 128
linear_value_head_dim: 128
linear_num_key_heads: 16
linear_num_value_heads: 32
linear_conv_kernel_dim: 4
max_position_embeddings: 262144
partial_rotary_factor: 0.25
rope_theta: 10000.0
rms_norm_eps: 1e-6
decoder_sparse_step: 1
moe_intermediate_size: 512
shared_expert_intermediate_size: 512
num_experts_per_tok: 10
num_experts: 512
norm_topk_prob: true
router_aux_loss_coef: 0.001
